# Система мониторинга дисциплины на занятиях

Интерактивное веб‑приложение на Streamlit для **обнаружения нарушений дисциплины** на занятиях по видеопотоку.  
Используются нейросетевые модели:

- **YOLO (Ultralytics)** — детекция нарушений/событий на кадре (сон, еда, телефон, бутылка и т.п.).[1]
- **InsightFace** — детекция и распознавание лиц (опционально, для идентификации).[2]

Приложение работает с **веб‑камерой** и **загруженными видеофайлами**, а также формирует **отчёты о нарушениях**.

***

## Возможности

- Онлайн‑мониторинг с камеры:
  - Детекция нарушений в реальном времени.
  - Отрисовка рамок и подписей на кадрах.
- Обработка видеофайлов:
  - Поддержка: MP4, AVI, MOV, MKV.
  - Вывод обработанного видео с боксами (опционально).
- Отчётность:
  - CSV‑отчёт по нарушениям.
  - Графики/статистика по типам нарушений.
  - Текстовый отчёт (под формат проектной работы).
- (Опционально) распознавание лиц:
  - Регистрация студентов по фото.
  - Привязка нарушений к конкретному человеку (если включено).

***

## Структура проекта

```text
monitoring_app/
│
├── app.py                   # Главная страница Streamlit (описание + настройки в сайдбаре)
├── config.py                # Пути к моделям + маппинг классов + параметры по умолчанию
├── models/
│   ├── __init__.py
│   ├── yolo_detector.py     # Обёртка над Ultralytics YOLO (детекция нарушений)
│   └── face_recognition.py  # InsightFace (детекция/эмбеддинги/поиск по базе)
├── utils/
│   ├── __init__.py
│   ├── video_processor.py   # Обработка видео/кадров, сбор нарушений
│   ├── report_generator.py  # CSV, графики и текстовый отчёт
│   └── visualization.py     # Вспомогательные функции визуализации
├── pages/
│   ├── 1_Регистрация Студентов.py        
│   ├── 2_Статистика.py    
│   ├── 3_Загрузка Видео.py    
│   └── 4_Веб Камера.py
└── requirements.txt      
```

***

## Установка

### 1) Перейти в папку проекта

```bash
cd monitoring_app
```

### 2) Создать виртуальное окружение (рекомендуется Python 3.10)

```bash
python -m venv .venv
# Windows:
.\.venv\Scripts\activate
# Linux/macOS:
# source .venv/bin/activate
```

### 3) Установить зависимости

```bash
pip install -r requirements.txt
```

> Примечание: InsightFace использует onnxruntime как backend для инференса (если включен модуль распознавания лиц).[2]

***

## Подготовка моделей

### YOLO веса (обязательно)
1. Скопируй файл весов (например `best.pt`) в корень проекта `monitoring_app/`.
2. Укажи путь в `config.py`:

```python
YOLO_MODEL_PATH = "best.pt"
```

### InsightFace (опционально)
Если нужен модуль распознавания лиц — укажи название модели:

```python
INSIGHTFACE_MODEL = "buffalo_l"
```

***

## Конфигурация (config.py)

Рекомендуется хранить в `config.py`:

- `YOLO_MODEL_PATH` — путь к весам (относительный или абсолютный).
- `VIOLATION_CLASSES` — словарь соответствия `id -> название нарушения` (чтобы подписывать боксы и отчёты).
- Значения по умолчанию:
  - `DEFAULT_CONFIDENCE = 0.5`
  - `DEFAULT_IOU = 0.45`

Пример (адаптируй под свои классы):

```python
YOLO_MODEL_PATH = "best.pt"

VIOLATION_CLASSES = {
    0: "курение",
    1: "еда",
    2: "сон",
    3: "телефон",
    4: "бутылка",
}

INSIGHTFACE_MODEL = "buffalo_l"

DEFAULT_CONFIDENCE = 0.5
DEFAULT_IOU = 0.45
```

***

## Запуск

```bash
streamlit run app.py
```

После запуска приложение доступно по адресу:  
http://localhost:8501

***

## Страницы приложения

- **Веб‑камера (Webcam)**  
  Для онлайн‑детекции нарушений (и, опционально, распознавания лиц).

- **Загрузка видео (Upload Video)**  
  Для обработки файла, сохранения размеченного видео и выгрузки отчётов.

- **Статистика (Statistics)**  
  Сводные метрики по нарушениям: количество, средняя уверенность, распределение по типам и т.п.

- **Регистрация (Register Student)** *(если используется)*  
  Добавление человека в базу (по фото) для дальнейшей идентификации.

***

## Отчёты и результаты

Рекомендуемая структура (можно настроить под себя):

```text
reports/
├── processed_video.mp4          # обработанное видео (если включено)
├── violations_report.csv        # CSV-отчёт
├── violations_report.txt        # текстовый отчёт
└── plots/
    ├── violations_pie.png
    └── violations_bar.png
```

Что обычно полезно хранить в CSV:
- timestamp/время (или номер кадра)
- тип нарушения
- confidence
- bbox (координаты)
- (если включено) имя распознанного человека

***

## Дизайн (опционально)

Можно добавить тему через `.streamlit/config.toml` (цвета/шрифт), чтобы интерфейс выглядел более “приложением”.[3]

***

## Типовые проблемы

- `FileNotFoundError: ... best.pt`  
  Проверь, что `YOLO_MODEL_PATH` указан без ведущего `\` и путь собирается корректно (лучше приводить к абсолютному через `Path(__file__)...`).

- Ошибки установки `onnxruntime`/`insightface`  
  Чаще всего решается использованием Python 3.10–3.11 и установкой зависимостей в чистом venv.

***

## Планы улучшений (Roadmap)

- Трекинг объектов (чтобы не считать одно и то же нарушение на соседних кадрах).
- Калибровка порогов confidence/IoU под каждый класс отдельно.
- Экспорт отчёта в PDF.
- Роли пользователей (преподаватель/админ) + простая авторизация.

***

## Благодарности

- Ultralytics YOLO за удобный инференс/тренировку и API.[1]
- InsightFace за модуль распознавания лиц.[2]
